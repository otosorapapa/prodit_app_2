# -*- coding: utf-8 -*-
"""
ECåç›Šç®¡ç†ã‚¢ãƒ—ãƒªï¼ˆæ¥½å¤©ä¸­å°äº‹æ¥­è€…å‘ã‘ï¼‰ â€” Streamlitå˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«å®Ÿè£…
è¦ä»¶å¯¾å¿œï¼š
- 0. ç›®çš„/KGI/KPIï¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰&é›†è¨ˆå¿œç­”é«˜é€ŸåŒ–ï¼ˆst.cache_dataï¼‰
- 1. åˆ©ç”¨è€…/æ¨©é™ï¼šã‚¢ãƒ—ãƒªå†…ã‚·ãƒ³ãƒ—ãƒ«èªè¨¼ + ãƒ­ãƒ¼ãƒ«ï¼ˆç®¡ç†è€…/çµŒå–¶è€…/æ‹…å½“è€…/ç›£æŸ»ï¼‰
- 2. æ©Ÿèƒ½è¦ä»¶ FR-001ã€œFR-007ï¼ˆMUSTï¼‰+ FR-101ã€œ105ï¼ˆSHOULDï¼‰+ æ‹¡å¼µä¸€éƒ¨
- 3. ç”»é¢è¦ä»¶ï¼šãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰/ãƒ‡ãƒ¼ã‚¿å–è¾¼/åœ¨åº«ç®¡ç†/åˆ©ç›Šåˆ†æ/è¿”å“ãƒ»ä¸è‰¯/RFM/è¨­å®š/ç›£æŸ»ãƒ­ã‚°
- 4. ãƒ‡ãƒ¼ã‚¿è¦ä»¶ï¼šSQLite+SQLAlchemyï¼ˆå‹&æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼‰ã€CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ/ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- 5. å¤–éƒ¨IFï¼šSlack Webhooké€šçŸ¥ã€PDFå‡ºåŠ›ï¼ˆreportlab/æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼‰
- 6. NFRï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ€é©åŒ–ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆZIPï¼‰ã€ç›£è¦–ãƒ­ã‚°
- 7. è¨­è¨ˆï¼šStreamlitå†…å®Œçµï¼ˆå°†æ¥FastAPIåˆ†é›¢å¯èƒ½ãªæ§‹é€ ï¼‰

â˜… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
pip install streamlit pandas numpy SQLAlchemy requests reportlab python-dateutil pytz openpyxl
# ï¼ˆä»»æ„ï¼‰SQLCipher æš—å·åŒ–åˆ©ç”¨æ™‚ï¼špip install pysqlcipher3
# å®Ÿè¡Œï¼šstreamlit run app.py

â˜… åˆæœŸãƒ­ã‚°ã‚¤ãƒ³ï¼ˆst.secretsæœªè¨­å®šæ™‚ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
- admin / admin ï¼ˆç®¡ç†è€…ï¼‰
- owner / owner ï¼ˆçµŒå–¶è€…ï¼‰
- staff / staff ï¼ˆæ‹…å½“è€…ï¼‰
- audit / audit ï¼ˆç›£æŸ»ï¼‰

â˜… secrets.toml ä¾‹ï¼ˆ.streamlit/secrets.tomlï¼‰
[auth]
admin = "pbkdf2:sha256:demo"  # ãƒ‡ãƒ¢ï¼šãƒ—ãƒ¬ãƒ¼ãƒ³ç…§åˆã‚‚å¯
owner = "owner"
staff = "staff"
audit = "audit"
[roles]
admin = "admin"
owner = "executive"
staff = "staff"
audit = "auditor"
[slack]
webhook_url = "https://hooks.slack.com/services/xxx/yyy/zzz"
[db]
path = "data/app.sqlite3"  # SQLCipherä½¿ç”¨æ™‚ã¯ "data/app.db" ã‚’PRAGMA keyã§æš—å·åŒ–
[app]
company_name = "ãã‚‰ã—ã„ãã„ãæ ªå¼ä¼šç¤¾"
lead_time_days = 14
safety_stock_default = 5

"""
import os
import io
import re
import json
import zipfile
from datetime import datetime, date, timedelta
from typing import Dict, List, Tuple, Optional

import numpy as np
import pandas as pd
import pytz
import requests
from dateutil.relativedelta import relativedelta

import streamlit as st
from sqlalchemy import (
    create_engine, Column, Integer, String, Date, DateTime, Float, Numeric, Boolean, Text, UniqueConstraint,
    ForeignKey, event
)
from sqlalchemy.orm import sessionmaker, declarative_base, relationship
from sqlalchemy.exc import IntegrityError

# =============== åŸºæœ¬è¨­å®š ===============
APP_TZ = pytz.timezone("Asia/Tokyo")
TODAY = datetime.now(APP_TZ).date()
DATA_DIR = "data"
UPLOAD_DIR = os.path.join(DATA_DIR, "uploads")
REPORT_DIR = os.path.join(DATA_DIR, "reports")
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(REPORT_DIR, exist_ok=True)

# =============== DB æ¥ç¶š ===============
Base = declarative_base()

def get_db_path() -> str:
    try:
        db_path = st.secrets["db"].get("path", os.path.join(DATA_DIR, "app.sqlite3"))
    except Exception:
        db_path = os.path.join(DATA_DIR, "app.sqlite3")
    return db_path

@st.cache_resource(show_spinner=False)
def get_engine():
    db_path = get_db_path()
    url = f"sqlite:///{db_path}"
    engine = create_engine(url, future=True)
    return engine

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=get_engine())

# =============== ã‚¹ã‚­ãƒ¼ãƒå®šç¾© ===============
class Order(Base):
    __tablename__ = "orders"
    id = Column(Integer, primary_key=True)
    order_id = Column(String, unique=True, index=True, nullable=False)
    order_date = Column(Date, index=True, nullable=False)
    channel = Column(String, index=True, default="Rakuten")
    buyer_id = Column(String, index=True)
    subtotal = Column(Numeric(14, 2), default=0)
    shipping_fee = Column(Numeric(14, 2), default=0)
    coupon_discount = Column(Numeric(14, 2), default=0)
    points_used = Column(Numeric(14, 2), default=0)
    platform_fee = Column(Numeric(14, 2), default=0)
    tax = Column(Numeric(14, 2), default=0)
    status = Column(String, default="paid")
    created_at = Column(DateTime, default=lambda: datetime.now(APP_TZ))

    items = relationship("OrderItem", back_populates="order", cascade="all, delete-orphan")

class OrderItem(Base):
    __tablename__ = "order_items"
    id = Column(Integer, primary_key=True)
    order_id = Column(String, ForeignKey("orders.order_id", ondelete="CASCADE"), index=True)
    sku = Column(String, index=True)
    qty = Column(Integer, default=0)
    unit_price = Column(Numeric(14, 2), default=0)
    cogs = Column(Numeric(14, 2), default=0)
    shipping_alloc = Column(Numeric(14, 2), default=0)
    fee_alloc = Column(Numeric(14, 2), default=0)
    ad_cost_alloc = Column(Numeric(14, 2), default=0)

    order = relationship("Order", back_populates="items")

class Product(Base):
    __tablename__ = "products"
    id = Column(Integer, primary_key=True)
    sku = Column(String, unique=True, index=True)
    product_name = Column(String)
    category = Column(String, index=True)
    cost = Column(Numeric(14, 2), default=0)
    price = Column(Numeric(14, 2), default=0)
    supplier = Column(String)
    safety_stock = Column(Integer, default=5)

class Inventory(Base):
    __tablename__ = "inventory"
    id = Column(Integer, primary_key=True)
    sku = Column(String, index=True)
    warehouse = Column(String, default="MAIN")
    qty_onhand = Column(Integer, default=0)
    qty_allocated = Column(Integer, default=0)
    updated_at = Column(DateTime, default=lambda: datetime.now(APP_TZ))
    __table_args__ = (UniqueConstraint("sku", "warehouse", name="uq_inv_sku_wh"),)

class Return(Base):
    __tablename__ = "returns"
    id = Column(Integer, primary_key=True)
    order_id = Column(String, index=True)
    sku = Column(String, index=True)
    qty = Column(Integer, default=0)
    reason = Column(String)
    defect_flag = Column(Boolean, default=False)
    restocked_flag = Column(Boolean, default=False)
    return_date = Column(Date, default=lambda: datetime.now(APP_TZ).date())

class AdCost(Base):
    __tablename__ = "ad_costs"
    id = Column(Integer, primary_key=True)
    date = Column(Date, index=True)
    campaign = Column(String, index=True)
    channel = Column(String, index=True, default="Rakuten")
    cost = Column(Numeric(14, 2), default=0)
    clicks = Column(Integer, default=0)
    impressions = Column(Integer, default=0)

class Fee(Base):
    __tablename__ = "fees"
    id = Column(Integer, primary_key=True)
    date = Column(Date, index=True)
    channel = Column(String, index=True, default="Rakuten")
    fee_type = Column(String)
    amount = Column(Numeric(14, 2), default=0)
    rule_id = Column(String)

class Customer(Base):
    __tablename__ = "customers"
    id = Column(Integer, primary_key=True)
    buyer_id = Column(String, unique=True, index=True)
    first_order = Column(Date)
    last_order = Column(Date)
    lifetime_value = Column(Numeric(14, 2), default=0)
    r = Column(Integer, default=0)
    f = Column(Integer, default=0)
    m = Column(Integer, default=0)

class Setting(Base):
    __tablename__ = "settings"
    id = Column(Integer, primary_key=True)
    key = Column(String, unique=True)
    value = Column(Text)  # JSONæ–‡å­—åˆ—

class AuditLog(Base):
    __tablename__ = "audit_logs"
    id = Column(Integer, primary_key=True)
    ts = Column(DateTime, default=lambda: datetime.now(APP_TZ))
    actor = Column(String)
    action = Column(String)
    detail = Column(Text)

class Snooze(Base):
    __tablename__ = "snoozes"
    id = Column(Integer, primary_key=True)
    sku = Column(String, index=True)
    until_ts = Column(DateTime)

# =============== åˆæœŸåŒ– ===============

def init_db():
    engine = get_engine()
    Base.metadata.create_all(engine)
    # æœ€ä½é™ã®è¨­å®šã®åˆæœŸåŒ–
    with SessionLocal() as db:
        if not db.query(Setting).filter_by(key="company_name").first():
            cname = st.secrets.get("app", {}).get("company_name", "è‡ªç¤¾EC")
            db.add(Setting(key="company_name", value=json.dumps(cname, ensure_ascii=False)))
        if not db.query(Setting).filter_by(key="lead_time_days").first():
            lead = st.secrets.get("app", {}).get("lead_time_days", 14)
            db.add(Setting(key="lead_time_days", value=json.dumps(int(lead))))
        if not db.query(Setting).filter_by(key="safety_stock_default").first():
            ss = st.secrets.get("app", {}).get("safety_stock_default", 5)
            db.add(Setting(key="safety_stock_default", value=json.dumps(int(ss))))
        db.commit()

# =============== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ===============

def log(action: str, detail: str = ""):
    actor = st.session_state.get("user", "guest")
    with SessionLocal() as db:
        db.add(AuditLog(actor=actor, action=action, detail=detail[:2000]))
        db.commit()

@st.cache_data(show_spinner=False)
def load_table_df(table_name: str) -> pd.DataFrame:
    engine = get_engine()
    df = pd.read_sql_table(table_name, engine)
    return df

@st.cache_data(show_spinner=False)
def read_csv_cached(file_bytes: bytes, encoding: str = "utf-8") -> pd.DataFrame:
    return pd.read_csv(io.BytesIO(file_bytes), encoding=encoding)

@st.cache_data(show_spinner=False)
def read_excel_cached(file_bytes: bytes, sheet_name: Optional[str] = None) -> pd.DataFrame:
    return pd.read_excel(io.BytesIO(file_bytes), sheet_name=sheet_name)

@st.cache_data(show_spinner=False)
def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")

# =============== èªè¨¼/æ¨©é™ ===============
ROLES = {
    "admin": ["dashboard", "import", "inventory", "profit", "returns", "rfm", "settings", "audit"],
    "executive": ["dashboard", "profit", "inventory", "rfm"],
    "staff": ["dashboard", "import", "inventory", "returns", "profit"],
    "auditor": ["audit"],
}

DEFAULT_USERS = {
    "admin": {"password": "admin", "role": "admin"},
    "owner": {"password": "owner", "role": "executive"},
    "staff": {"password": "staff", "role": "staff"},
    "audit": {"password": "audit", "role": "auditor"},
}

def resolve_users_from_secrets() -> Dict[str, Dict[str, str]]:
    users = {}
    try:
        auth = st.secrets.get("auth", {})
        roles = st.secrets.get("roles", {})
        for uname, pwd in auth.items():
            role = roles.get(uname, "staff")
            users[uname] = {"password": str(pwd), "role": role}
    except Exception:
        pass
    if not users:
        users = DEFAULT_USERS
    return users


def login_panel():
    users = resolve_users_from_secrets()
    st.sidebar.markdown("### ãƒ­ã‚°ã‚¤ãƒ³")
    if st.session_state.get("user"):
        st.sidebar.markdown(
            f"ğŸ‘¤ **{st.session_state['user']}** (ãƒ­ãƒ¼ãƒ«: {st.session_state['role']})"
        )
        if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            log("logout", st.session_state.get("user"))
            for k in ["user", "role"]:
                if k in st.session_state:
                    del st.session_state[k]
            st.experimental_rerun()
        st.sidebar.markdown("---")
    else:
        uname = st.sidebar.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")
        pwd = st.sidebar.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
        if st.sidebar.button("ãƒ­ã‚°ã‚¤ãƒ³"):
            if uname in users and str(pwd) == str(users[uname]["password"]):
                st.session_state["user"] = uname
                st.session_state["role"] = users[uname]["role"]
                st.sidebar.success(
                    f"{uname} ã¨ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã€‚ãƒ­ãƒ¼ãƒ«: {st.session_state['role']}"
                )
                log("login", f"user={uname}")
            else:
                st.sidebar.error(
                    "èªè¨¼å¤±æ•—ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼å/ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
                )


def role_allows(page_key: str) -> bool:
    role = st.session_state.get("role")
    if not role:
        return False
    return page_key in ROLES.get(role, [])

# =============== Slack é€šçŸ¥ ===============

def send_slack(text: str):
    url = st.secrets.get("slack", {}).get("webhook_url")
    if not url:
        return False, "webhookæœªè¨­å®š"
    try:
        r = requests.post(url, json={"text": text}, timeout=10)
        return r.status_code == 200, r.text
    except Exception as e:
        return False, str(e)

# =============== ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ› ===============
REQUIRED_MAP = {
    "orders": ["order_id", "order_date", "channel", "buyer_id", "subtotal", "shipping_fee", "coupon_discount", "points_used", "platform_fee", "tax", "status"],
    "order_items": ["order_id", "sku", "qty", "unit_price", "cogs", "shipping_alloc", "fee_alloc", "ad_cost_alloc"],
    "products": ["sku", "product_name", "category", "cost", "price", "supplier", "safety_stock"],
    "inventory": ["sku", "warehouse", "qty_onhand", "qty_allocated", "updated_at"],
    "returns": ["order_id", "sku", "qty", "reason", "defect_flag", "restocked_flag", "return_date"],
    "ad_costs": ["date", "campaign", "channel", "cost", "clicks", "impressions"],
    "fees": ["date", "channel", "fee_type", "amount", "rule_id"],
    "customers": ["buyer_id", "first_order", "last_order", "lifetime_value"],
}

TABLE_CLASS = {
    "orders": Order,
    "order_items": OrderItem,
    "products": Product,
    "inventory": Inventory,
    "returns": Return,
    "ad_costs": AdCost,
    "fees": Fee,
    "customers": Customer,
}


def save_mapping(name: str, mapping: Dict[str, str]):
    with SessionLocal() as db:
        db.merge(Setting(key=f"mapping:{name}", value=json.dumps(mapping, ensure_ascii=False)))
        db.commit()


def load_mapping(name: str) -> Dict[str, str]:
    with SessionLocal() as db:
        row = db.query(Setting).filter_by(key=f"mapping:{name}").first()
        if row:
            return json.loads(row.value)
        return {}


def normalize_df(df: pd.DataFrame, mapping: Dict[str, str], required_cols: List[str]) -> pd.DataFrame:
    # mapping: {app_col -> source_col}
    out = pd.DataFrame()
    for col in required_cols:
        src = mapping.get(col)
        if src in df.columns:
            out[col] = df[src]
        else:
            out[col] = np.nan
    # å‹æ•´å½¢
    if "order_date" in out.columns:
        out["order_date"] = pd.to_datetime(out["order_date"], errors="coerce").dt.date
    if "return_date" in out.columns:
        out["return_date"] = pd.to_datetime(out["return_date"], errors="coerce").dt.date
    if "updated_at" in out.columns:
        out["updated_at"] = pd.to_datetime(out["updated_at"], errors="coerce")
    # æ•°å€¤ç³»
    num_cols = [c for c in out.columns if c not in ["order_id", "order_date", "channel", "buyer_id", "sku", "product_name", "category", "supplier", "status", "fee_type", "campaign", "rule_id", "warehouse", "reason", "return_date", "updated_at"]]
    for c in num_cols:
        out[c] = pd.to_numeric(out[c], errors="coerce").fillna(0)
    # æ–‡å­—
    str_cols = ["order_id", "channel", "buyer_id", "sku", "product_name", "category", "supplier", "status", "fee_type", "campaign", "rule_id", "warehouse", "reason"]
    for c in str_cols:
        if c in out.columns:
            out[c] = out[c].fillna("").astype(str)
    return out


def upsert_dataframe(df: pd.DataFrame, table: str, pk: Optional[str] = None):
    engine = get_engine()
    cls = TABLE_CLASS[table]
    with SessionLocal() as db:
        if table == "orders" and pk == "order_id":
            # é‡è¤‡é˜²æ­¢ï¼šæœªå­˜åœ¨ã®æ³¨æ–‡ã®ã¿è¿½åŠ 
            exist_ids = set([r[0] for r in db.query(Order.order_id).filter(Order.order_id.in_(df["order_id"].unique().tolist())).all()])
            insert_df = df[~df["order_id"].isin(exist_ids)].copy()
            if not insert_df.empty:
                insert_df.to_sql(table, engine, if_exists="append", index=False, method="multi")
            added = len(insert_df)
            skipped = len(df) - added
            log("import_orders", f"added={added}, skipped={skipped}")
            return added, skipped
        else:
            df.to_sql(table, engine, if_exists="append", index=False, method="multi")
            log("import_table", f"table={table}, rows={len(df)}")
            return len(df), 0

# =============== æŒ‡æ¨™è¨ˆç®— ===============

@st.cache_data(show_spinner=False)
def get_profit_frame(date_from: date, date_to: date, channels: List[str], categories: List[str]) -> pd.DataFrame:
    eng = get_engine()
    orders = pd.read_sql_query(
        "SELECT * FROM orders WHERE order_date BETWEEN :f AND :t",
        eng,
        params={"f": date_from, "t": date_to},
        parse_dates=["order_date"],
    )
    items = pd.read_sql_table("order_items", eng)
    products = pd.read_sql_table("products", eng)
    ad = pd.read_sql_query(
        "SELECT date, channel, SUM(cost) AS ad_cost FROM ad_costs WHERE date BETWEEN :f AND :t GROUP BY date, channel",
        eng,
        params={"f": date_from, "t": date_to},
        parse_dates=["date"],
    )
    if channels:
        orders = orders[orders["channel"].isin(channels)]
        ad = ad[ad["channel"].isin(channels)] if not ad.empty else ad
    df = items.merge(orders, on="order_id", how="inner", suffixes=("_i", "_o"))
    df = df.merge(products[["sku", "category"]], on="sku", how="left")
    if categories:
        df = df[df["category"].isin(categories)]

    # æ³¨æ–‡ãƒ¬ãƒ™ãƒ«å€¤å¼•ï¼ˆcoupon/pointsï¼‰ã‚’æ˜ç´°æŒ‰åˆ†
    rev_by_order = df.groupby("order_id")["unit_price"].sum().rename("order_rev")
    df = df.join(rev_by_order, on="order_id")
    for col in ["coupon_discount", "points_used", "shipping_fee", "platform_fee", "tax", "subtotal"]:
        if col not in df.columns:
            df[col] = 0
    df["rev"] = df["unit_price"].astype(float) * df["qty"].astype(float)
    share = (df["rev"] / df["order_rev"]).replace([np.inf, -np.inf], 0).fillna(0)
    df["coupon_alloc"] = share * df["coupon_discount"].astype(float)
    df["points_alloc"] = share * df["points_used"].astype(float)
    df["ship_alloc_order"] = share * df["shipping_fee"].astype(float)
    df["platfee_alloc_order"] = share * df["platform_fee"].astype(float)

    # åç›Šåˆ†è§£
    for c in ["cogs", "shipping_alloc", "fee_alloc", "ad_cost_alloc"]:
        if c not in df.columns:
            df[c] = 0
    df["ad_alloc_total"] = df["ad_cost_alloc"].astype(float)  # itemãƒ¬ãƒ™ãƒ«ã®äº‹å‰æŒ‰åˆ†
    df["fee_total"] = df["fee_alloc"].astype(float) + df["platfee_alloc_order"].astype(float)
    df["ship_total"] = df["shipping_alloc"].astype(float) + df["ship_alloc_order"].astype(float)
    df["discount_total"] = df["coupon_alloc"].astype(float) + df["points_alloc"].astype(float)

    df["gross_profit"] = df["rev"].astype(float) - (
        df["cogs"].astype(float) + df["ship_total"] + df["fee_total"] + df["ad_alloc_total"] - df["discount_total"]
    )
    df["profit_margin"] = np.where(df["rev"]>0, df["gross_profit"] / df["rev"], np.nan)

    return df

@st.cache_data(show_spinner=False)
def kpi_summary(df: pd.DataFrame) -> Dict[str, float]:
    sales = float(df["rev"].sum())
    gp = float(df["gross_profit"].sum())
    pm = (gp / sales) if sales > 0 else 0
    ad = float(df.get("ad_alloc_total", pd.Series([0]*len(df))).sum())
    return {"sales": sales, "gp": gp, "pm": pm, "ad": ad}

@st.cache_data(show_spinner=False)
def abc_by_sku(df: pd.DataFrame) -> pd.DataFrame:
    s = df.groupby("sku")["gross_profit"].sum().sort_values(ascending=False)
    cum = s.cumsum() / s.sum() if s.sum() != 0 else s.cumsum()
    out = pd.DataFrame({"gp": s, "cum_share": cum})
    out["class"] = pd.cut(out["cum_share"], bins=[0, 0.8, 0.95, 1.0], labels=["A", "B", "C"], include_lowest=True)
    out = out.reset_index()
    return out

@st.cache_data(show_spinner=False)
def returns_rate(date_from: date, date_to: date) -> float:
    eng = get_engine()
    sold = pd.read_sql_query(
        "SELECT SUM(qty) AS qty FROM order_items oi JOIN orders o ON oi.order_id=o.order_id WHERE o.order_date BETWEEN :f AND :t",
        eng, params={"f": date_from, "t": date_to},
    )["qty"].fillna(0).iloc[0]
    ret = pd.read_sql_query(
        "SELECT SUM(qty) AS qty FROM returns WHERE return_date BETWEEN :f AND :t",
        eng, params={"f": date_from, "t": date_to}
    )["qty"].fillna(0).iloc[0]
    return float(ret) / float(sold) if sold else 0.0

# =============== éœ€è¦äºˆæ¸¬ v1ï¼ˆç§»å‹•å¹³å‡/å˜å›å¸°ï¼‰ ===============
@st.cache_data(show_spinner=False)
def forecast_sku_monthly(sales_df: pd.DataFrame, periods: int = 1) -> pd.DataFrame:
    """sales_df: columns=[order_date, sku, qty] æœˆæ¬¡é›†è¨ˆå¾Œã«äºˆæ¸¬ã€‚"""
    if sales_df.empty:
        return pd.DataFrame(columns=["sku", "yhat"])
    g = sales_df.copy()
    g["ym"] = pd.to_datetime(g["order_date"]).dt.to_period("M").dt.to_timestamp()
    m = g.groupby(["sku", "ym"])["qty"].sum().reset_index()
    out_rows = []
    for sku, sub in m.groupby("sku"):
        sub = sub.sort_values("ym")
        # ç§»å‹•å¹³å‡
        ma = sub["qty"].rolling(3, min_periods=1).mean()
        # å˜å›å¸°ï¼ˆæ™‚é–“â†’æ•°é‡ï¼‰
        x = np.arange(len(sub))
        if len(sub) >= 2:
            coef = np.polyfit(x, sub["qty"].values, 1)
            trend_next = np.polyval(coef, len(sub))
        else:
            trend_next = sub["qty"].iloc[-1]
        yhat = float((ma.iloc[-1] + trend_next) / 2)
        out_rows.append({"sku": sku, "yhat": max(yhat, 0)})
    return pd.DataFrame(out_rows)

# =============== RFM åˆ†æ ===============
@st.cache_data(show_spinner=False)
def rfm_scores(date_ref: date) -> pd.DataFrame:
    eng = get_engine()
    orders = pd.read_sql_table("orders", eng, parse_dates=["order_date"])  
    items = pd.read_sql_table("order_items", eng)
    df = items.merge(orders, on="order_id", how="inner")
    df["amount"] = df["unit_price"].astype(float) * df["qty"].astype(float)
    agg = df.groupby("buyer_id").agg(
        last_order=("order_date", "max"),
        freq=("order_id", "nunique"),
        monetary=("amount", "sum"),
    ).reset_index()
    agg["recency_days"] = (pd.to_datetime(date_ref) - agg["last_order"]).dt.days
    # äº”åˆ†ä½ã‚¹ã‚³ã‚¢ï¼ˆRã¯å°ã•ã„ã»ã©è‰¯ã„â†’é€†é †ï¼‰
    agg["R"] = pd.qcut(agg["recency_days"].rank(method="first", ascending=True), 5, labels=[5,4,3,2,1]).astype(int)
    agg["F"] = pd.qcut(agg["freq"].rank(method="first", ascending=False), 5, labels=[5,4,3,2,1]).astype(int)
    agg["M"] = pd.qcut(agg["monetary"].rank(method="first", ascending=False), 5, labels=[5,4,3,2,1]).astype(int)
    agg["RFM"] = agg["R"].astype(str) + agg["F"].astype(str) + agg["M"].astype(str)
    return agg

# =============== åœ¨åº«/ã‚¢ãƒ©ãƒ¼ãƒˆ ===============
@st.cache_data(show_spinner=False)
def inventory_alerts() -> pd.DataFrame:
    eng = get_engine()
    inv = pd.read_sql_table("inventory", eng)
    prod = pd.read_sql_table("products", eng)
    df = inv.merge(prod[["sku", "product_name", "category", "safety_stock"]], on="sku", how="left")
    df["safety_stock"].fillna(load_int("safety_stock_default", 5), inplace=True)
    df["alert"] = df["qty_onhand"] < df["safety_stock"]
    return df[df["alert"]]

# =============== è¨­å®šãƒ­ãƒ¼ãƒ‰/ä¿å­˜ ===============

def save_setting(key: str, value):
    with SessionLocal() as db:
        db.merge(Setting(key=key, value=json.dumps(value, ensure_ascii=False)))
        db.commit()

@st.cache_data(show_spinner=False)
def load_setting(key: str, default=None):
    with SessionLocal() as db:
        row = db.query(Setting).filter_by(key=key).first()
        if row:
            return json.loads(row.value)
        return default

def load_int(key: str, default: int) -> int:
    v = load_setting(key, default)
    try:
        return int(v)
    except Exception:
        return default

# =============== PDF å‡ºåŠ› ===============

def make_dashboard_pdf(summary: Dict[str, float], abc_table: pd.DataFrame) -> bytes:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4, landscape
    from reportlab.lib.units import mm
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont

    buffer = io.BytesIO()
    c = canvas.Canvas(buffer, pagesize=landscape(A4))

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆHeiseiMin-W3ï¼‰
    try:
        pdfmetrics.registerFont(UnicodeCIDFont("HeiseiMin-W3"))
        font_name = "HeiseiMin-W3"
    except Exception:
        font_name = "Helvetica"

    c.setFont(font_name, 16)
    c.drawString(20*mm, 190*mm, f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚µãƒãƒªãƒ¼ï¼ˆ{datetime.now(APP_TZ).strftime('%Y-%m-%d')}ï¼‰")

    c.setFont(font_name, 12)
    y = 175*mm
    def row(lbl, val):
        nonlocal y
        c.drawString(20*mm, y, f"{lbl}")
        c.drawRightString(260*mm, y, f"{val:,.0f}")
        y -= 8*mm

    row("å£²ä¸Š", summary.get("sales", 0))
    row("ç²—åˆ©", summary.get("gp", 0))
    row("åˆ©ç›Šç‡(%)", summary.get("pm", 0) * 100)
    row("åºƒå‘Šè²»", summary.get("ad", 0))

    # ABCä¸Šä½
    c.drawString(20*mm, y, "ABCä¸Šä½ï¼ˆä¸Šä½10ä»¶ï¼‰")
    y -= 8*mm
    top = abc_table.head(10)
    for _, r in top.iterrows():
        c.drawString(25*mm, y, f"{r['sku']}")
        c.drawRightString(200*mm, y, f"GP: {r['gp']:,.0f}")
        c.drawRightString(260*mm, y, f"ç´¯è¨ˆ: {r['cum_share']*100:,.1f}% / {r['class']}")
        y -= 6*mm

    c.showPage()
    c.save()
    pdf = buffer.getvalue()
    buffer.close()
    return pdf

# =============== ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— ===============

def make_backup_zip() -> bytes:
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, 'w', zipfile.ZIP_DEFLATED) as z:
        db_path = get_db_path()
        if os.path.exists(db_path):
            z.write(db_path, arcname=os.path.basename(db_path))
        for root, _, files in os.walk(UPLOAD_DIR):
            for f in files:
                full = os.path.join(root, f)
                arc = os.path.relpath(full, DATA_DIR)
                z.write(full, arc)
    return buf.getvalue()

# =============== UI æ§‹ç¯‰ ===============

def sidebar_filters():
    st.sidebar.markdown("### å…±é€šãƒ•ã‚£ãƒ«ã‚¿")
    today = TODAY
    start = st.sidebar.date_input("é–‹å§‹æ—¥", value=today - relativedelta(months=1))
    end = st.sidebar.date_input("çµ‚äº†æ—¥", value=today)
    eng = get_engine()
    try:
        channels = pd.read_sql_query("SELECT DISTINCT channel FROM orders", eng)["channel"].dropna().tolist()
    except Exception:
        channels = []
    ch_sel = st.sidebar.multiselect("ãƒãƒ£ãƒãƒ«", options=channels, default=channels)
    try:
        categories = pd.read_sql_query("SELECT DISTINCT category FROM products", eng)["category"].dropna().tolist()
    except Exception:
        categories = []
    cat_sel = st.sidebar.multiselect("ã‚«ãƒ†ã‚´ãƒª", options=categories)
    return start, end, ch_sel, cat_sel


def page_dashboard():
    st.header("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    start, end, ch, cat = sidebar_filters()
    with st.spinner("é›†è¨ˆä¸­..."):
        df = get_profit_frame(start, end, ch, cat)
    summ = kpi_summary(df)

    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("å£²ä¸Š", f"{summ['sales']:,.0f}")
    c2.metric("ç²—åˆ©", f"{summ['gp']:,.0f}")
    c3.metric("åˆ©ç›Šç‡", f"{summ['pm']*100:,.1f}%")
    c4.metric("åºƒå‘Šè²»", f"{summ['ad']:,.0f}")
    rr = returns_rate(start, end)
    c5.metric("è¿”å“ç‡", f"{rr*100:,.2f}%")

    st.markdown("#### æ¨ç§»")
    if not df.empty:
        ts = df.groupby(pd.to_datetime(df["order_date"]).dt.date).agg(sales=("rev", "sum"), gp=("gross_profit", "sum"))
        st.line_chart(ts)
        by_ch = df.groupby("channel")["rev"].sum().sort_values(ascending=False)
        st.bar_chart(by_ch)
    else:
        st.info("å¯¾è±¡æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    st.markdown("#### SKUåˆ¥è²¢çŒ®ï¼ˆParetoï¼‰/ åœ¨åº«ã‚¢ãƒ©ãƒ¼ãƒˆ / è¿”å“ç‡Top")
    colA, colB = st.columns([2,1])
    abc = abc_by_sku(df) if not df.empty else pd.DataFrame()
    with colA:
        if not abc.empty:
            st.dataframe(abc.head(100))
            csv = df_to_csv_bytes(abc)
            st.download_button("ABCä¸Šä½CSV", csv, file_name="abc_top.csv", mime="text/csv")
    with colB:
        alerts = inventory_alerts()
        if not alerts.empty:
            st.dataframe(alerts[["sku","product_name","qty_onhand","safety_stock","warehouse"]])
            if st.button("Slacké€šçŸ¥ï¼ˆåœ¨åº«ã‚¢ãƒ©ãƒ¼ãƒˆTopé€ä¿¡ï¼‰"):
                top = alerts.head(10).copy()
                text = "åœ¨åº«ã‚¢ãƒ©ãƒ¼ãƒˆ\n" + "\n".join([f"{r.sku} {r.product_name} æ®‹:{r.qty_onhand}/é–¾:{r.safety_stock}" for _, r in top.iterrows()])
                ok, resp = send_slack(text)
                st.success("é€ä¿¡ã—ã¾ã—ãŸ" if ok else f"å¤±æ•—: {resp}")

    # PDFã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    if st.button("PDFãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ï¼ˆA4æ¨ªï¼‰"):
        pdf = make_dashboard_pdf(summ, abc)
        st.download_button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: dashboard.pdf", data=pdf, file_name="dashboard.pdf", mime="application/pdf")


def page_import():
    st.header("ãƒ‡ãƒ¼ã‚¿å–è¾¼ï¼ˆCSV/Excelï¼‰")
    st.caption("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ä¸€æ‹¬å–è¾¼ã€ãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜å¯ã€‚é‡è¤‡æ³¨æ–‡ã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚")

    tab1, tab2 = st.tabs(["ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ãƒãƒƒãƒ”ãƒ³ã‚°ç®¡ç†"])

    with tab1:
        target_table = st.selectbox("å–è¾¼å…ˆãƒ†ãƒ¼ãƒ–ãƒ«", list(REQUIRED_MAP.keys()), index=0)
        mapping = load_mapping(target_table)
        uploaded = st.file_uploader("CSV/Excelã‚’é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰", type=["csv","xlsx","xls"], accept_multiple_files=True)
        if uploaded:
            for uf in uploaded:
                st.write(f"**{uf.name}**")
                content = uf.read()
                # ä¿å­˜
                with open(os.path.join(UPLOAD_DIR, uf.name), "wb") as fp:
                    fp.write(content)
                # èª­ã¿è¾¼ã¿
                if uf.type in ("application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", "application/vnd.ms-excel") or uf.name.endswith((".xlsx",".xls")):
                    df = read_excel_cached(content)
                    if isinstance(df, dict):
                        # æœ€åˆã®ã‚·ãƒ¼ãƒˆ
                        df = list(df.values())[0]
                else:
                    df = read_csv_cached(content)
                st.write("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆå…ˆé ­100è¡Œï¼‰")
                st.dataframe(df.head(100))

                # ãƒãƒƒãƒ”ãƒ³ã‚°UI
                required = REQUIRED_MAP[target_table]
                st.markdown("##### é …ç›®ãƒãƒƒãƒ”ãƒ³ã‚°")
                mcols = {}
                for col in required:
                    src = st.selectbox(f"{col}", options=[""] + list(df.columns), index=( [""] + list(df.columns) ).index(mapping.get(col, "")) if mapping.get(col, "") in df.columns else 0, key=f"map_{uf.name}_{col}")
                    if src:
                        mcols[col] = src
                if st.button(f"ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–è¾¼ï¼ˆ{uf.name}ï¼‰", key=f"import_{uf.name}"):
                    norm = normalize_df(df, mcols, required)
                    added, skipped = upsert_dataframe(norm, target_table, pk="order_id" if target_table=="orders" else None)
                    st.success(f"å–è¾¼æˆåŠŸï¼šè¿½åŠ  {added} ä»¶ / ã‚¹ã‚­ãƒƒãƒ— {skipped} ä»¶")
                    log("import", f"table={target_table}, file={uf.name}, add={added}, skip={skipped}")

        st.divider()
        if st.button("ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆDB+ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰ZIPä½œæˆ"):
            z = make_backup_zip()
            st.download_button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: backup.zip", data=z, file_name="backup.zip", mime="application/zip")

    with tab2:
        st.markdown("#### å–è¾¼ãƒãƒƒãƒ”ãƒ³ã‚°ä¿å­˜/èª­è¾¼")
        target_table2 = st.selectbox("å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«", list(REQUIRED_MAP.keys()), index=0, key="map_table")
        current = load_mapping(target_table2)
        st.json(current)
        if st.button("ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆä¸Šã®UIã§æœ€å¾Œã«é¸ã‚“ã ã‚‚ã®ï¼‰ã‚’ä¿å­˜", help="UIã®é¸æŠçŠ¶æ…‹ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚­ãƒ¼ä»˜ã‘ã•ã‚Œã¾ã™ã€‚ä¿å­˜ã¯ãƒ†ãƒ¼ãƒ–ãƒ«å˜ä½ã§é›†ç´„ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã‹ã‚‰å›å
            required = REQUIRED_MAP[target_table2]
            mcols = {}
            for col in required:
                # æœ€å¾Œã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«åãŒã‚­ãƒ¼ã«è¼‰ã‚‹ãŸã‚ã€ç›´è¿‘ã®å€¤ã‚’æ‹¾ã†
                for k in list(st.session_state.keys())[::-1]:
                    if k.startswith("map_") and k.endswith(col):
                        v = st.session_state[k]
                        if v:
                            mcols[col] = v
                            break
            if mcols:
                save_mapping(target_table2, mcols)
                st.success("ä¿å­˜ã—ã¾ã—ãŸ")
            else:
                st.info("ä¿å­˜å¯¾è±¡ã®ãƒãƒƒãƒ”ãƒ³ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä¸Šã‚¿ãƒ–ã§ä¸€åº¦é¸æŠã—ã¦ãã ã•ã„ã€‚")


def page_inventory():
    st.header("åœ¨åº«ç®¡ç†")
    # ä¸€è¦§
    eng = get_engine()
    inv = pd.read_sql_table("inventory", eng)
    prod = pd.read_sql_table("products", eng)
    df = inv.merge(prod[["sku","product_name","category","safety_stock"]], on="sku", how="left")
    st.dataframe(df)

    st.markdown("#### é–¾å€¤è¨­å®šã¨ã‚¢ãƒ©ãƒ¼ãƒˆ")
    default_ss = load_int("safety_stock_default", 5)
    new_default = st.number_input("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®‰å…¨åœ¨åº«", min_value=0, value=default_ss)
    if st.button("ä¿å­˜ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®‰å…¨åœ¨åº«ï¼‰"):
        save_setting("safety_stock_default", int(new_default))
        st.success("ä¿å­˜ã—ã¾ã—ãŸ")

    alerts = inventory_alerts()
    st.markdown("##### ã‚¢ãƒ©ãƒ¼ãƒˆä¸€è¦§")
    if alerts.empty:
        st.success("åœ¨åº«ã‚¢ãƒ©ãƒ¼ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.dataframe(alerts)
        if st.button("Slacké€šçŸ¥ï¼ˆå…¨ä»¶ï¼‰"):
            text = "åœ¨åº«ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆå…¨ä»¶ï¼‰\n" + "\n".join([f"{r.sku} {r.product_name} æ®‹:{r.qty_onhand}/é–¾:{r.safety_stock}" for _, r in alerts.iterrows()])
            ok, resp = send_slack(text)
            st.success("é€ä¿¡ã—ã¾ã—ãŸ" if ok else f"å¤±æ•—: {resp}")


def page_profit():
    st.header("åˆ©ç›Šåˆ†æï¼ˆåç›Šåˆ†è§£ãƒ”ãƒœãƒƒãƒˆï¼‰")
    start, end, ch, cat = sidebar_filters()
    with st.spinner("ãƒ”ãƒœãƒƒãƒˆé›†è¨ˆ..."):
        df = get_profit_frame(start, end, ch, cat)
    if df.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    dims = st.multiselect("æ¬¡å…ƒï¼ˆåˆ—ï¼‰", ["order_date","channel","category","sku"], default=["order_date","channel"])
    metrics = st.multiselect("æŒ‡æ¨™", ["rev","gross_profit","profit_margin","cogs","ship_total","fee_total","ad_alloc_total","discount_total","qty"], default=["rev","gross_profit","profit_margin"])

    tmp = df.copy()
    tmp["qty"] = tmp["qty"].astype(float)
    pivot = tmp.pivot_table(index=dims, values=[m for m in metrics if m in tmp.columns], aggfunc={m: np.sum for m in metrics if m != "profit_margin"}, observed=False)
    if "profit_margin" in metrics:
        gp = tmp.groupby(dims)["gross_profit"].sum()
        rv = tmp.groupby(dims)["rev"].sum()
        pm = (gp/rv).replace([np.inf, -np.inf], np.nan)
        pivot["profit_margin"] = pm
    pivot = pivot.fillna(0).reset_index()
    st.dataframe(pivot.head(1000))

    st.download_button("CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", df_to_csv_bytes(pivot), file_name="profit_pivot.csv")


def page_returns():
    st.header("è¿”å“ãƒ»ä¸è‰¯ç®¡ç†")
    eng = get_engine()
    df = pd.read_sql_table("returns", eng)
    st.dataframe(df.tail(500))

    st.markdown("#### è¿”å“ç™»éŒ²ï¼ˆåœ¨åº«ã¸åŒæ™‚åæ˜ ï¼‰")
    with st.form("ret_form"):
        order_id = st.text_input("æ³¨æ–‡ID")
        sku = st.text_input("SKU")
        qty = st.number_input("æ•°é‡", min_value=1, value=1)
        reason = st.text_input("ç†ç”±ã‚¿ã‚°", value="ä¸è‰¯")
        defect = st.checkbox("ä¸è‰¯ãƒ•ãƒ©ã‚°", value=True)
        restock = st.checkbox("åœ¨åº«æˆ»ã—", value=True)
        rdate = st.date_input("è¿”å“æ—¥", value=TODAY)
        sub = st.form_submit_button("ç™»éŒ²")
    if sub:
        with SessionLocal() as db:
            db.add(Return(order_id=order_id, sku=sku, qty=int(qty), reason=reason, defect_flag=defect, restocked_flag=restock, return_date=rdate))
            if restock:
                inv = db.query(Inventory).filter_by(sku=sku, warehouse="MAIN").first()
                if not inv:
                    inv = Inventory(sku=sku, warehouse="MAIN", qty_onhand=0, qty_allocated=0)
                    db.add(inv)
                inv.qty_onhand += int(qty)
                inv.updated_at = datetime.now(APP_TZ)
            db.commit()
        st.success("ç™»éŒ²ã—ã¾ã—ãŸ")
        log("return_reg", f"order={order_id}, sku={sku}, qty={qty}")
        st.experimental_rerun()


def page_rfm():
    st.header("RFMåˆ†æ & é¡§å®¢æŠ½å‡º")
    ref = st.date_input("åŸºæº–æ—¥", value=TODAY)
    df = rfm_scores(ref)
    st.dataframe(df)

    # ä¸Šä½ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡ºï¼ˆä¾‹ï¼šR>=4, F>=4, M>=4ï¼‰
    st.markdown("#### ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡º")
    rmin = st.slider("Ræœ€å°", 1, 5, 4)
    fmin = st.slider("Fæœ€å°", 1, 5, 4)
    mmin = st.slider("Mæœ€å°", 1, 5, 4)
    seg = df[(df.R>=rmin)&(df.F>=fmin)&(df.M>=mmin)].copy()
    st.dataframe(seg)
    st.download_button("CSVå‡ºåŠ›ï¼ˆä¸Šä½ã‚»ã‚°ï¼‰", df_to_csv_bytes(seg), file_name="rfm_top.csv")


def page_settings():
    st.header("è¨­å®š / ãƒ—ãƒ©ã‚°ã‚¤ãƒ³åŒ– / é€šçŸ¥ãƒ«ãƒ¼ãƒ«")
    st.subheader("Slack/å¸³ç¥¨/DB")
    st.text_input("Slack Webhookï¼ˆsecrets.toml æ¨å¥¨ï¼‰", value=st.secrets.get("slack", {}).get("webhook_url", ""), disabled=True, help=".streamlit/secrets.toml ã«è¨­å®šã—ã¦ãã ã•ã„")
    lead = st.number_input("ç™ºæ³¨ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼ˆæ—¥ï¼‰", min_value=0, value=load_int("lead_time_days", 14))
    if st.button("ä¿å­˜ï¼ˆãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼‰"):
        save_setting("lead_time_days", int(lead))
        st.success("ä¿å­˜ã—ã¾ã—ãŸ")

    st.subheader("é€šçŸ¥ãƒ«ãƒ¼ãƒ«ï¼ˆç²—åˆ©/åœ¨åº«/è¿”å“ï¼‰")
    rules_json = load_setting("notify_rules", {"gp_drop_pct": 20, "returns_rate_pct": 5})
    rules_text = st.text_area("JSON ã§è¨­å®š", value=json.dumps(rules_json, ensure_ascii=False, indent=2), height=180)
    if st.button("ä¿å­˜ï¼ˆé€šçŸ¥ãƒ«ãƒ¼ãƒ«ï¼‰"):
        try:
            save_setting("notify_rules", json.loads(rules_text))
            st.success("ä¿å­˜ã—ã¾ã—ãŸ")
        except Exception as e:
            st.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")

    st.subheader("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    if st.button("å‹˜å®šç§‘ç›®CSVãƒãƒƒãƒ”ãƒ³ã‚°è¡¨ï¼ˆé››å½¢ï¼‰"):
        df = pd.DataFrame({"account":["å£²ä¸Š","ä»•å…¥","é€æ–™","æ‰‹æ•°æ–™","åºƒå‘Šè²»","ã‚¯ãƒ¼ãƒãƒ³","ãƒã‚¤ãƒ³ãƒˆ","ç¨é‡‘"],"column":["rev","cogs","ship_total","fee_total","ad_alloc_total","coupon_alloc","points_alloc","tax"]})
        st.download_button("download.csv", df_to_csv_bytes(df), file_name="account_mapping_template.csv")


def page_audit():
    st.header("ç›£æŸ»ãƒ­ã‚° / ç›£è¦–")
    eng = get_engine()
    try:
        logs = pd.read_sql_table("audit_logs", eng)
        logs = logs.sort_values("ts", ascending=False).head(2000)
        st.dataframe(logs)
        st.download_button("CSVã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ", df_to_csv_bytes(logs), file_name="audit_logs.csv")
    except Exception:
        st.info("ãƒ­ã‚°ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

# =============== é€šçŸ¥ï¼ˆSHOULD FR-104ï¼‰ ===============

def run_threshold_checks():
    rules = load_setting("notify_rules", {"gp_drop_pct": 20, "returns_rate_pct": 5})
    end = TODAY
    start = end - relativedelta(months=1)
    prev_start = start - relativedelta(months=1)
    prev_end = start
    df_now = get_profit_frame(start, end, [], [])
    df_prev = get_profit_frame(prev_start, prev_end, [], [])
    gp_now = float(df_now["gross_profit"].sum()) if not df_now.empty else 0
    gp_prev = float(df_prev["gross_profit"].sum()) if not df_prev.empty else 0
    drop = 100.0 * (gp_prev - gp_now) / gp_prev if gp_prev else 0
    rr = returns_rate(start, end) * 100

    texts = []
    if drop >= rules.get("gp_drop_pct", 20):
        texts.append(f"ç²—åˆ©æ€¥æ¸›: å‰æœˆæ¯” -{drop:.1f}%")
    if rr >= rules.get("returns_rate_pct", 5):
        texts.append(f"è¿”å“ç‡é«˜æ­¢ã¾ã‚Š: {rr:.2f}%")
    if texts:
        send_slack("\n".join(texts))

# =============== ãƒ¡ã‚¤ãƒ³ ===============

def main():
    st.set_page_config(page_title="ECåç›Šç®¡ç†", page_icon="ğŸ›ï¸", layout="wide")
    init_db()

    st.sidebar.title("ECåç›Šç®¡ç†ï¼ˆStreamlitï¼‰")
    login_panel()

    if not st.session_state.get("user"):
        st.info("å·¦ã®ãƒ‘ãƒãƒ«ã§ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚åˆæœŸã¯ admin/admin ãªã©ã€‚")
        return

    company = load_setting("company_name", st.secrets.get("app", {}).get("company_name", "è‡ªç¤¾EC"))
    st.sidebar.markdown(f"**äº‹æ¥­è€…ï¼š{company}**")

    # ãƒšãƒ¼ã‚¸é¸æŠï¼ˆãƒ­ãƒ¼ãƒ«ã«å¿œã˜ã¦åˆ¶é™ï¼‰
    pages = [
        ("dashboard", "ğŸ“Š ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", page_dashboard),
        ("import", "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–è¾¼", page_import),
        ("inventory", "ğŸ“¦ åœ¨åº«ç®¡ç†", page_inventory),
        ("profit", "ğŸ’¹ åˆ©ç›Šåˆ†æ", page_profit),
        ("returns", "â™»ï¸ è¿”å“ãƒ»ä¸è‰¯", page_returns),
        ("rfm", "ğŸ‘¥ RFM/é¡§å®¢", page_rfm),
        ("settings", "âš™ï¸ è¨­å®š", page_settings),
        ("audit", "ğŸ“ ç›£æŸ»ãƒ­ã‚°", page_audit),
    ]
    avail = {k: v for k, v in ROLES.items()}  # å‚ç…§
    options = [label for key, label, _ in pages if role_allows(key)]
    label2func = {label: fn for key, label, fn in pages if role_allows(key)}
    choice = st.sidebar.radio("ãƒ¡ãƒ‹ãƒ¥ãƒ¼", options=options, index=0)
    log("nav", choice)

    # è‡ªå‹•ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ï¼‰
    if st.sidebar.button("ã—ãã„å€¤ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆSlacké€šçŸ¥ï¼‰"):
        run_threshold_checks()
        st.sidebar.success("ãƒã‚§ãƒƒã‚¯å®Œäº†")

    # æç”»
    label2func[choice]()

if __name__ == "__main__":
    main()
